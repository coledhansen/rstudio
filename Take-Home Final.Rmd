---
title: "BSAN 450 Take Home Final"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(e1071)
library(tidyverse)
library(dplyr)
```

# Problem 1

### Setup
```{r}
banknotes = read.csv("Banknotes.csv")
set.seed(1)
train=sample(1372,686)
test=(c(1:1372)[-train])
Notes_train=banknotes[train,]
Notes_test=banknotes[test,]
```

### Tuning Setup
```{r}
Cost_values = c(0.001, 0.01, 0.1, 1, 5, 10, 100)
Degree_values = c(2, 3, 4, 5, 6)
Gamma_values = c(0.5, 1, 5, 10)
```

### Tuning
```{r}
# Linear
set.seed(0)
tune_linear = tune(svm, as.factor(Class) ~ Variance + Skewness, data = Notes_train,
                   kernel = 'linear', type = 'C',
                   ranges = list(cost = Cost_values))

tune_linear$best.parameters
  # cost = 0.1
best_linear = tune_linear$best.model

preds_linear = predict(best_linear, Notes_test)
class_matrix = table(Truth = Notes_test$Class, Predictions = preds_linear)
class_matrix

acc_linear = ((class_matrix[1,1] + class_matrix[2,2]) / NROW(Notes_test))
acc_linear
  # accuracy rate = 0.8994169, ~90%
```

```{r}
# Polynomial
set.seed(0)
tune_polynomial = tune(svm,as.factor(Class) ~ Variance + Skewness ,data=Notes_train, 
                       kernel = 'polynomial', type='C',
                       ranges = list(cost=Cost_values, degree = Degree_values))

tune_polynomial$best.parameters
  # cost = 100
  # degree = 3
best_polynomial = tune_polynomial$best.model

preds_polynomial = predict(best_polynomial,Notes_test)
class_matrix=table(Truth = Notes_test$Class, Predictions = preds_polynomial)
class_matrix

acc_polynomial <-(class_matrix[1,1]+class_matrix[2,2])/NROW(Notes_test)
acc_polynomial
  # accuracy rate = 0.8702624
```

```{r}
# Radial
set.seed(0)
tune_radial = tune(svm, as.factor(Class) ~ Variance + Skewness, data = Notes_train,
                   kernel = 'radial', type = 'C',
                   ranges = list(cost = Cost_values, gamma = Gamma_values))

tune_radial$best.parameters
  # cost = 10
  # gamma = 5
best_radial = tune_radial$best.model

preds_radial = predict(best_radial, Notes_test)
class_matrix = table(Truth = Notes_test$Class, Predictions = preds_radial)
class_matrix

acc_radial = ((class_matrix[1,1] + class_matrix[2,2]) / NROW(Notes_train))
acc_radial
  # accuracy rate = 0.9402332, ~94%
```

# Best Model
```{r}
# Best tuned model for accuracy rate was the RADIAL kernel with cost = 10 and gamma = 5.

# Plot
plot(best_radial, Notes_train, Skewness ~ Variance)

# Classification Matrix
class_matrix = table(Truth = Notes_test$Class, Predictions = preds_radial)
class_matrix

# Accuracy Rate
acc_radial = ((class_matrix[1,1] + class_matrix[2,2]) / NROW(Notes_train))
acc_radial
  # accuracy rate = 0.9402332, ~94%
```

# Decision Tree
```{r}
library(tree)

set.seed(0)
tree = tree(as.factor(Class) ~ Variance + Skewness + Curtosis + Entropy,
            data = Notes_train)

plot(tree)
text(tree)
title('Decision Tree')
```

```{r}
set.seed(0)

cv.tree.notes = cv.tree(tree, FUN = prune.misclass, K = 10)

plot(cv.tree.notes$size, cv.tree.notes$dev,type="b", 
     xlab = 'Number of terminal nodes', ylab = 'Misclassifications', 
     main = 'Misclassifications vs. Number of Terminal Nodes')
min(cv.tree.notes$dev)

```

```{r}
prune.misclass = prune.misclass(tree, best = 5)

plot(prune.misclass)
title('Classifying Bank Notes with 5 Terminal Nodes')
text(prune.misclass)
```

```{r}
set.seed(0)
preds_prune = predict(prune.misclass, Notes_test, type = 'class')
class_matrix = table(Truth = Notes_test$Class, Predictions = preds_prune)
class_matrix

acc_prune = (class_matrix[1,1]+class_matrix[2,2]) / NROW(Notes_test)
acc_prune
  # accuracy = 0.9387755, or ~94%
```

### Conclusion
```{r}
# Figure it out here
```

# Problem 2

### Setup
```{r}
auto = read.csv("Auto.csv")
set.seed(2)
ids = sample(392, 30)
auto_sample = auto[ids,]
rownames(auto_sample) = auto[ids,]$name
```

### Additional Setup
```{r}
library(dplyr)
car_select_vars = select(auto_sample, c('weight', 'displacement'))
car_select_vars_scaled = scale(car_select_vars)
rownames(car_select_vars_scaled) = rownames(auto_sample)
```

### K-Means
```{r}
set.seed(0)

T_WSS = rep(10)

for (i in 1:10){
kmeans_fit = kmeans(car_select_vars_scaled, centers = i, nstart = 20)
T_WSS[i] = kmeans_fit$tot.withinss
}

plot(T_WSS[1:10], type = 'b', xlab = 'K', ylab = 'Total Within-Cluster Sum of Squares', 
     main = 'Total Within-Cluster Sum of Squares vs. K')
```

```{r}
set.seed(0)

kmeans_fit = kmeans(car_select_vars_scaled, centers = 3, nstart = 20)
kmeans_fit

### Plot
plot(weight~displacement, data = car_select_vars_scaled, col = kmeans_fit$cluster, 
     main="K-Means Clustering Results with K=3")

### Define
# Cluster 1: low displacement, low weight
# Cluster 2: medium displacement, medium height
# Cluster 3: high displacement, high weight

### List
# Cluster 1 (green, bottom left): 7
  # cadillac eldorado, plymouth satelitte custom (sw), pontiac catalina,
  # buick centry luxus (sw), ford thunderbird, ford country squire (sw),
  # chevrolet impala

# Cluster 2 (red, middle of graph): 10
  # dodge aspen se, buick regal sport coupe (turbo), audi 5000,
  # buick century limited, volvo 244dl, oldsmobile omega brougham,
  # ford granada gl, amc hornet sportabout (sw), peugeot 504, plymouth satelitte sebring

# Cluster 3 (black, top right): 13
  # plymouth champ, ford escord 2h, toyota corolla, chevrolet vega,
  # mazda glc custom l, datsun 310, datsun 1200, ford pinto,
  # volkswagen dasher, plymouth horizon miser, datsun 610, datsun 710,
  # subaru dl

### Evaluate.
# Evaluate the average value of horsepower for each cluster.
```

### Hierarchical
```{r}
set.seed(0)

hc.complete = hclust(dist(car_select_vars_scaled), method ="complete")
plot_complete = plot(hc.complete, main = 'Complete Linkage', xlab = "Cars", sub = "", 
     cex = 0.6)

hc.complete$height
  # Height of cut that achieves 4 clusters = 0.92597096

# Cluster 1:
  # ford thunderbird, chevrolet impala, plymouth satellite custom (sw),
  # cadillac eldorado, ford country squire (sw), pontiac catalina,
  # buickc century luxus (sw)

# Cluster 2:
  # volkswagen dasher, toyota corolla, plymouth horizon miser,
  # ford pinto, ford escort 2h, datsun 610, datsun 1200,
  # plymouth champ, datsun 310, datsun 710,
  # mazda glc custom l, subaru dl

# Cluster 3:
  # chevrolet vega, oldsmobile omega brougham,
  # peugeot 504, audi 5000, volvo 244dl

# Cluster 4:
  # buick regal sport coupe (turbo), dodge aspen se,
  # plymouth satellite sebring, amc hornet sportabout (sw),
  # buick century limited, ford granada gl

# Evaluate the average value of horsepower for each cluster.
```
